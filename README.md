# Meta-analysis on Swish and ReLU Activation Function Families
Comparing why the Swish activation function family has made accuracy imrpovements over the ReLU activation function family.

## Overview

This can be seen in comparisons of smoothness, self-gatededness, saturation, preconditioning, and empirics. 

### Smoothness Comparisons 

### Convergence Comparisons

### Empirical Comparisons (MNIST)

## Download 

The paper is available to download here. 